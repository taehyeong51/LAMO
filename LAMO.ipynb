{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taehyeong51/LAMO/blob/main/LAMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1q5RTx3AXF6"
      },
      "source": [
        "# **당신의 더욱 완벽한 추억을 위해**\n",
        "\n",
        "Mask2Former(MMDetection) : https://github.com/open-mmlab/mmdetection.git\n",
        "\n",
        "Lama : https://github.com/saic-mdal/lama\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1AsWI5RN66aQEprOnNQj_ryV27-YS8NNJ\" height = 300 width = 1000>\n",
        "\n",
        "이미지 내 불필요한 인물 객체를 제거하여 당신이 원하는 더욱 완벽한 사진을 생성할 수 있습니다.\n",
        "\n",
        "[MMDetection](https://github.com/open-mmlab/mmdetection.git) 기반의 [Mask2Former](https://github.com/open-mmlab/mmdetection/tree/master/configs/mask2former)를 기반으로 인물을 탐지하여 mask를 생성하고 [LaMa](https://github.com/saic-mdal/lama) 를 기반으로 mask 영역의 이미지를 새롭게 생성하였습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRM-NzSrwpqX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">MMDetection 진행을 위한 환경 구축</b>\n",
        "#@markdown 3-5분 정도 소요됩니다\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "!pip3 install rich\n",
        "!pip3 install modelindex\n",
        "\n",
        "!mim install mmcv-full\n",
        "\n",
        "%cd /content\n",
        "!pip3 install torch\n",
        "!pip install torchvision\n",
        "!pip3 install rich\n",
        "!pip3 install modelindex\n",
        "!pip3 install openmim\n",
        "!mim install mmcv-full\n",
        "\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "\n",
        "%cd /content/mmdetection\n",
        "\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install -v -e .\n",
        "\n",
        "# download pth(checkpoint) file of Mask2Former\n",
        "!gdown https://download.openmmlab.com/mmdetection/v2.0/mask2former/mask2former_swin-s-p4-w7-224_lsj_8x2_50e_coco/mask2former_swin-s-p4-w7-224_lsj_8x2_50e_coco_20220504_001756-743b7d99.pth\n",
        "!mkdir /content/mmdetection/checkpoints\n",
        "!mv /content/mmdetection/mask2former_swin-s-p4-w7-224_lsj_8x2_50e_coco_20220504_001756-743b7d99.pth /content/mmdetection/checkpoints\n",
        "\n",
        "!mkdir /content/input_lama\n",
        "!mkdir /content/result\n",
        "print(\"MMDetection 환경 구축 소요시간 : {}분\".format(round((time.time() - start)/60,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbEh-_jrnNGQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">LaMa 환경 구축</b>\n",
        "#@markdown 6-7분 정도 소요됩니다\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "%cd /content\n",
        "# Run this sell to set everything up\n",
        "print('\\n> Cloning the repo')\n",
        "!git clone https://github.com/saic-mdal/lama.git\n",
        "\n",
        "print('\\n> Install dependencies')\n",
        "!pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 torchtext==0.9\n",
        "!pip install -r lama/requirements.txt --quiet\n",
        "!pip install wget --quiet\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html --quiet\n",
        "\n",
        "\n",
        "print('\\n> Changing the dir to:')\n",
        "%cd /content/lama\n",
        "!export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)\n",
        "# % export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)\n",
        "\n",
        "\n",
        "\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o big-lama.zip\n",
        "!unzip big-lama.zip\n",
        "\n",
        "print('>fixing opencv')\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet\n",
        "\n",
        "%cd /content/lama\n",
        "!export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)\n",
        "\n",
        "print(\"LaMa 환경 구축 소요시간 : {}분\".format(round((time.time() - start)/60,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_q_5T9IGRJw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">segmentation 모델 설정 → Mask2Former</b>\n",
        "% cd /content/mmdetection\n",
        "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mmcv\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "config_file = 'configs/mask2former/mask2former_swin-s-p4-w7-224_lsj_8x2_50e_coco.py'\n",
        "checkpoint_file = 'checkpoints/mask2former_swin-s-p4-w7-224_lsj_8x2_50e_coco_20220504_001756-743b7d99.pth'\n",
        "\n",
        "# build the model from a config file and a checkpoint file\n",
        "model = init_detector(config_file, checkpoint_file, device='cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZfsYPYGJJM7"
      },
      "source": [
        "# <b>이미지 준비</b>\n",
        "이미지를 업로드 해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2LFFBaKyCLJN"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">이미지 업로드</b>\n",
        "\n",
        "from google.colab import files\n",
        "import shutil \n",
        "\n",
        "def upload_file():\n",
        "    uploaded = files.upload()\n",
        "    try:\n",
        "        fn = list(uploaded.keys())[0]\n",
        "    except:\n",
        "        print (\"Please upload a valid image file!\")\n",
        "        raise StopExecution\n",
        "    print('Uploaded file \"{name}\" of {length} bytes'.format(name=fn,length=len(uploaded[fn])))\n",
        "    return fn\n",
        "\n",
        "\n",
        "print (\"이미지를 업로드 해 주세요\")\n",
        "fn = upload_file()\n",
        "shutil.move(fn, \"/content/mmdetection/demo/test.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7TKPUfBehse"
      },
      "source": [
        "# <b>인물 선택</b>\n",
        "이미지 내에서 제거할 인물을 선택해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tORDYglWXDoT"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">인물 선택</b>\n",
        "\n",
        "from ipywidgets import Button, HBox, VBox, widgets, Checkbox\n",
        "\n",
        "img = '/content/mmdetection/demo/test.jpg'\n",
        "name = img.split(\"/\")[4].split(\".\")[0]\n",
        "original = cv2.imread(img)\n",
        "shape_ori = original.shape\n",
        "\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result)\n",
        "\n",
        "original_img = cv2.imread(img)\n",
        "analysis = np.array(result)\n",
        "processed_img = original_img.copy()\n",
        "\n",
        "### 사람찾기\n",
        "\n",
        "### people 의 신뢰도만 갖는 np array 생성\n",
        "n = len(analysis[0][0])\n",
        "list_people = [0 for i in range(n)]\n",
        "\n",
        "for i in range(len(analysis[0][0])):\n",
        "  if analysis[0][0][i][4] > 0.3:\n",
        "    list_people[i] = analysis[0][0][i][4]\n",
        "\n",
        "\n",
        "shape = original_img.shape\n",
        "mask_img = np.zeros((shape), dtype = np.uint8)\n",
        "### range(n), n에 해당하는 만큼의 대상 delete\n",
        "\n",
        "def gonogo(gonogo_img, people, information):\n",
        "  cnt = 0\n",
        "  for i in range(len(people)):\n",
        "\n",
        "\n",
        "    guy = max(people)\n",
        "    idx = people.index(guy)\n",
        "    if guy < 0.2:\n",
        "      pass\n",
        "    else:\n",
        "      xmin,ymin,xmax,ymax = map(round,information[0][0][idx][:4])\n",
        "      cnt += 1\n",
        "\n",
        "      target = information[1][0][idx]*1\n",
        "      (w, h), _ = cv2.getTextSize(\n",
        "        \"person {}\".format(int(cnt)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
        "      \n",
        "      blue = (255, 0, 0)\n",
        "      font =  cv2.FONT_HERSHEY_PLAIN\n",
        "      if i // 2 == 0:\n",
        "        y = -10\n",
        "      else:\n",
        "        y = 30\n",
        "      gonogo_img = cv2.putText(gonogo_img, \"person {}\".format(int(cnt)), (int((xmax+xmin)/2-30), ymin+y), font, 1, (255,255,255), 1, cv2.LINE_AA)\n",
        "      \n",
        "      people[idx] = 0\n",
        "  return gonogo_img, cnt\n",
        "\n",
        "\n",
        "gonogo_img, p_cnt = gonogo(processed_img, list_people, analysis)\n",
        "cv2_imshow(gonogo_img)\n",
        "\n",
        "output = widgets.Output()\n",
        "print (\"\")\n",
        "print (\"\")\n",
        "print (\"제거할 인물의 인덱스를 선택해주세요\")\n",
        "numbers = [widgets.Checkbox(value=False, description=str(i+1)) for i in range(p_cnt)]\n",
        "output = widgets.VBox(children=numbers)\n",
        "display(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask 생성"
      ],
      "metadata": {
        "id": "F9TU6RbbeCpx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DNoTVaAylWfV"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\"> instance segmentation</b>\n",
        "\n",
        "\n",
        "selected_data = []\n",
        "for i in range(0, len(numbers)):\n",
        "    if numbers[i].value == True:\n",
        "        selected_data.append(int([numbers[i].description][0])-1)\n",
        "\n",
        "name = img.split(\"/\")[4].split(\".\")[0]\n",
        "original = cv2.imread(img)\n",
        "shape_ori = original.shape\n",
        "\n",
        "### 변수선언\n",
        "original_img = cv2.imread(img)\n",
        "analysis = np.array(result)\n",
        "processed_img = original_img.copy()\n",
        "\n",
        "### 사람찾기\n",
        "\n",
        "### people 의 신뢰도만 갖는 np array 생성\n",
        "n = len(analysis[0][0])\n",
        "list_people = [0 for i in range(n)]\n",
        "\n",
        "for i in range(len(analysis[0][0])):\n",
        "  if analysis[0][0][i][4] > 0.3:\n",
        "    list_people[i] = analysis[0][0][i][4]\n",
        "\n",
        "\n",
        "shape = original_img.shape\n",
        "mask_img = np.zeros((shape), dtype = np.uint8)\n",
        "### range(n), n에 해당하는 만큼의 대상 delete\n",
        "cnt = 0\n",
        "for i in range(len(list_people)):\n",
        "                        \n",
        "  \n",
        "  guy = max(list_people)\n",
        "  idx = list_people.index(guy)\n",
        "  if i not in selected_data:\n",
        "    pass\n",
        "  else:\n",
        "    cnt += 1\n",
        "\n",
        "    target = analysis[1][0][idx]*1\n",
        "    mask = np.array(target.copy(), dtype = np.uint8) # 0~255로 변환\n",
        "    mask_reverse = np.array(analysis[1][0][idx]*255, dtype=np.uint8)\n",
        "\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "\n",
        "    dst = cv2.dilate(mask_img, k)\n",
        "    \n",
        "    ch_b = original_img[:,:,0]\n",
        "    ch_g = original_img[:,:,1]\n",
        "    ch_r = original_img[:,:,2]\n",
        "\n",
        "    filtered_img = cv2.merge((ch_b*mask, ch_g*mask, ch_r*mask)) # target only\n",
        "    filtered_img2 = cv2.merge((mask*255, mask*255, mask*255))\n",
        "\n",
        "    filtered_img = cv2.dilate(filtered_img,k)\n",
        "    filtered_img2 = cv2.dilate(filtered_img2,k)\n",
        "\n",
        "    processed_img = cv2.addWeighted(processed_img ,1, filtered_img2, 0.5,0)\n",
        "    \n",
        "    mask1d_img = mask_img[:,:,0] + mask_reverse\n",
        "    \n",
        "\n",
        "    mask_reverse = cv2.merge((mask_reverse,mask_reverse,mask_reverse))\n",
        "    mask_img = mask_img + mask_reverse\n",
        "\n",
        "  list_people[idx] = 0\n",
        "  \n",
        "mask_img = cv2.dilate(mask_img,k)\n",
        "mask1d1_img = cv2.dilate(mask1d_img,k)\n",
        "mask1d2_img = cv2.dilate(mask1d1_img, k, iterations = 10)\n",
        "\n",
        "cv2.imwrite(\"/content/result/masked_img.png\", processed_img)\n",
        "cv2.imwrite(\"/content/result/mask_img.png\", mask_img)\n",
        "\n",
        "cv2.imwrite(\"/content/result/{}.png\".format(name),original_img )\n",
        "\n",
        "# for LaMa\n",
        "\n",
        "cv2.imwrite(\"/content/input_lama/{}_mask01.png\".format(name), mask1d1_img)\n",
        "cv2.imwrite(\"/content/input_lama/{}_mask02.png\".format(name), mask1d2_img)\n",
        "cv2.imwrite(\"/content/input_lama/{}.png\".format(name),original_img )\n",
        "\n",
        "print(\"complete :)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5oO50uf9IoXs"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">object detection</b>\n",
        "\n",
        "### 변수선언\n",
        "original_img = cv2.imread(img)\n",
        "analysis = np.array(result)\n",
        "processed_img = original_img.copy()\n",
        "# showme(processed_img)\n",
        "\n",
        "### 사람찾기\n",
        "\n",
        "### people 의 신뢰도만 갖는 np array 생성\n",
        "n = len(analysis[0][0])\n",
        "list_people = [0 for i in range(n)]\n",
        "\n",
        "for i in range(len(analysis[0][0])):\n",
        "  if analysis[0][0][i][4] > 0.5:\n",
        "    list_people[i] = analysis[0][0][i][4]\n",
        "\n",
        "shape = original_img.shape\n",
        "mask_img = np.zeros((shape), dtype = np.uint8)\n",
        "### range(n), n에 해당하는 만큼의 대상 delete\n",
        "cnt = 0\n",
        "for i in range(len(list_people)):\n",
        "  guy = max(list_people)\n",
        "  idx = list_people.index(guy)\n",
        "  if i not in selected_data:\n",
        "    pass\n",
        "  else:\n",
        "    cnt += 1\n",
        "    ## bounding box procedure\n",
        "    xmin,ymin,xmax,ymax = map(round,analysis[0][0][idx][:4])\n",
        "    ymax = int(ymax * float(1.01))\n",
        "    white = (255,255,255)\n",
        "\n",
        "    mask_img = cv2.rectangle(mask_img, (xmin, ymin), (xmax, ymax),white,-1 )\n",
        "    invert_img = np.invert(mask_img)\n",
        "    if i == 0:\n",
        "      processed_img = cv2.bitwise_and(original_img, invert_img)\n",
        "    else:\n",
        "      processed_img = cv2.bitwise_and(processed_img, invert_img)\n",
        "    \n",
        "\n",
        "\n",
        "  list_people[idx] = 0\n",
        "  \n",
        "\n",
        "\n",
        "# for mmediting\n",
        "\n",
        "cv2.imwrite(\"/content/result/bbox_masked_img.png\", processed_img)\n",
        "cv2.imwrite(\"/content/result/bbox_mask_img.png\", mask_img)\n",
        "\n",
        "# for LaMa\n",
        "cv2.imwrite(\"/content/input_lama/{}.png\".format(name), original_img)\n",
        "cv2.imwrite(\"/content/input_lama/{}_mask03.png\".format(name), mask_img)\n",
        "\n",
        "\n",
        "print(\"complete :)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inpainting by LaMa"
      ],
      "metadata": {
        "id": "-oCiTJ58q_Gh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "237mb42SpYwa"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">Inpainting by LaMa</b>\n",
        "\n",
        "\n",
        "% cd /content/lama\n",
        "\n",
        "!export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)\n",
        "\n",
        "# !python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/test_lama outdir= /content/result/result_bbox_inpainting_lama.png\n",
        "!PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=/content/input_lama outdir=/content/result\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgcwmmps8QIq"
      },
      "source": [
        "# 결과\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k77BcG48ONE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">Inpainting 결과 확인</b>\n",
        "\n",
        "\n",
        "original = cv2.imread(\"/content/result/test.png\")\n",
        "result = cv2.imread(\"/content/result/test_mask02.png\")\n",
        "\n",
        "cv2_imshow(original)\n",
        "cv2_imshow(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erDozbpS3ddV"
      },
      "source": [
        "# Re-inpainting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVqX_Tva2FiM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"black\">다시 mask 적용 후 inpainting</b>\n",
        "\n",
        "!mkdir /content/input_lama2\n",
        "!mkdir /content/result2\n",
        "\n",
        "!cp -r /content/result/test_mask02.png /content/input_lama2/test_seg.png\n",
        "!cp -r /content/result/test_mask03.png /content/input_lama2/test_bbox.png\n",
        "\n",
        "!cp -r /content/input_lama/test_mask02.png /content/input_lama2/test_seg_mask01.png\n",
        "!cp -r /content/input_lama/test_mask02.png /content/input_lama2/test_bbox_mask01.png\n",
        "\n",
        "!cp -r /content/input_lama/test_mask03.png /content/input_lama2/test_seg_mask02.png\n",
        "!cp -r /content/input_lama/test_mask03.png /content/input_lama2/test_bbox_mask02.png\n",
        "\n",
        "%cd /content/lama\n",
        "!export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)\n",
        "\n",
        "# !python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/test_lama outdir= /content/result/result_bbox_inpainting_lama.png\n",
        "!PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=/content/input_lama2 outdir=/content/result2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-Inpainting 결과 확인"
      ],
      "metadata": {
        "id": "6Vi30Li3qw4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color=\"black\">Re-inpainting 결과 확인</b>\n",
        "\n",
        "import time\n",
        "\n",
        "result = cv2.imread(\"/content/result/test_mask02.png\")\n",
        "result2 = cv2.imread(\"/content/result2/test_seg_mask02.png\")\n",
        "\n",
        "cv2_imshow(original)\n",
        "print(\"original\")\n",
        "# time.sleep(3)\n",
        "\n",
        "cv2_imshow(result)\n",
        "print(\"Processed once\")\n",
        "# time.sleep(3)\n",
        "\n",
        "cv2_imshow(result2)\n",
        "print(\"Processed Twice\")\n"
      ],
      "metadata": {
        "id": "YAN8qBT4cpCa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "M1q5RTx3AXF6",
        "F9TU6RbbeCpx",
        "-oCiTJ58q_Gh",
        "erDozbpS3ddV"
      ],
      "name": "LAMO.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}